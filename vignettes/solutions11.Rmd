---
title: "Chapter 11: Statistical learning"
author: "Robin Lovelace, Jakub Nowosad, Jannes Muenchow"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{geocompr-solutions11}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, echo = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
```

## Prerequisites {-}

The solutions assume the following packages are attached (other packages will be attached when needed):

```{r packages, message=FALSE, warning=FALSE}
library(sf)
library(raster)
library(dplyr)
library(spData)
# library(RSAGA)
library(qgisprocess)
# library(mlr3)
library(tmap)
```

# Chapter 11

1) Compute the following terrain attributes from the `dem` datasets loaded with `data("landslides", package = "RSAGA")` with the help of R-GIS bridges (see this [Chapter](https://geocompr.robinlovelace.net/gis.html#gis)):
    - Slope
    - Plan curvature
    - Profile curvature
    - Catchment area
    
```{r, eval=FALSE}
# attach data
data("landslides", package = "RSAGA")

# DATA PREPROCESSING
#*******************

# select non-landslide points
non_pts = filter(landslides, lslpts == FALSE)
# select landslide points
lsl_pts = filter(landslides, lslpts == TRUE)
# randomly select 175 non-landslide points
set.seed(11042018)
non_pts_sub = sample_n(non_pts, size = nrow(lsl_pts))
# create smaller landslide dataset (lsl)
lsl = bind_rows(non_pts_sub, lsl_pts)

# digital elevation model
dem = 
  raster(dem$data, 
         crs = "+proj=utm +zone=17 +south +datum=WGS84 +units=m +no_defs",
         xmn = dem$header$xllcorner, 
         xmx = dem$header$xllcorner + dem$header$ncols * dem$header$cellsize,
         ymn = dem$header$yllcorner,
         ymx = dem$header$yllcorner + dem$header$nrows * dem$header$cellsize)

# COMPUTING TERRAIN ATTRIBUTES
#*******************************

algs = qgis_algorithms()
set_env(dev = FALSE)
dplyr::filter(algs, grepl("curvature", algorithm))
alg = "saga:slopeaspectcurvature"
qgis_show_help(alg)
qgis_arguments(alg)
# terrain attributes (ta)
out_nms = paste0(tempdir(), "/", c("aspect", "slope", "cplan", "cprof"), ".sdat")
args = rlang::set_names(out_nms, c("ASPECT", "SLOPE", "C_PLAN", "C_PROF"))

out = qgis_run_algorithm(alg, ELEVATION = dem, METHOD = 6, 
                         UNIT_SLOPE = "[1] degree",
                         UNIT_ASPECT = "[1] degree",
                         !!!args
                         )
# use brick because then the layers will be in memory and not on disk
ta = brick(lapply(out[names(args)], \(x) x[1]))
# hillshade (needs radians)
# hs = hillShade(ta$SLOPE * pi / 180, ta$ASPECT * pi / 180, 40, 270)
# plot(hs, col = gray(seq(0, 1, length.out = 100)), legend = FALSE)
# plot(dem, add = TRUE, alpha = 0.6)
# dplyr::filter(lsl, lslpts == TRUE) |> 
#   sf::st_as_sf(coords = c("x", "y"), crs = 32717) |>
#   plot(add = TRUE, pch = 16)

ta = raster::dropLayer(ta, "ASPECT")
names(ta) = c("slope", "cplan", "cprof")
# catchment area
dplyr::filter(algs, grepl("[Cc]atchment", algorithm))
alg = "saga:catchmentarea"
qgis_show_help(alg)
qgis_arguments(alg)
carea = qgis_run_algorithm(alg,
                           ELEVATION = dem, 
                           METHOD = 4, 
                           FLOW = file.path(tempdir(), "carea.sdat"))
# transform carea
carea = raster(carea$FLOW[1])
log10_carea = log10(carea)
names(log10_carea) = "log10_carea"
names(dem) = "elev"
# add log_carea
ta = addLayer(x = ta, dem, log10_carea)
```

2) Extract the values from the corresponding output rasters to the `landslides` data frame (`data(landslides, package = "RSAGA"`) by adding new variables called `slope`, `cplan`, `cprof`, `elev` and `log_carea`. Keep all landslide initiation points and 175 randomly selected non-landslide points (see this [section](https://geocompr.robinlovelace.net/spatial-cv.html#case-landslide) for details).

```{r, eval=FALSE}
# attach terrain attribute raster stack (in case you have skipped the previous
# exercise)
data("ta", package = "spDataLarge")
# extract values to points, i.e., create predictors
lsl[, names(ta)] = raster::extract(ta, lsl[, c("x", "y")])
```

3) Use the derived terrain attribute rasters in combination with a GLM to make a spatial prediction map similar to that shown in this [Figure](https://geocompr.robinlovelace.net/spatial-cv.html#fig:lsl-susc).
Running `data("study_mask", package = "spDataLarge")` attaches a mask of the study area.

```{r, eval=FALSE}
# attach data (in case you have skipped exercises 1) and 2)
# landslide points with terrain attributes and terrain attribute raster stack
data("lsl", "ta", package = "spDataLarge")

# fit the model
fit = glm(lslpts ~ slope + cplan + cprof + elev + log10_carea, 
          data = lsl, family = binomial())

# make the prediction
pred = raster::predict(object = ta, model = fit, type = "response")

# make the map
lsl_sf = st_as_sf(lsl, coords = c("x", "y"), crs = 32717)
hs = hillShade(ta$slope * pi / 180, terrain(ta$elev, opt = "aspect"))
rect = tmaptools::bb_poly(hs)
bbx = tmaptools::bb(hs, xlim = c(-0.02, 1), ylim = c(-0.02, 1), relative = TRUE)
tm_shape(hs, bbox = bbx) +
  tm_grid(col = "black", n.x = 1, n.y = 1, labels.inside.frame = FALSE,
          labels.rot = c(0, 90)) +
  tm_raster(palette = "white", legend.show = FALSE) +
  # hillshade
  tm_shape(mask(hs, study_area), bbox = bbx) +
	tm_raster(palette = gray(0:100 / 100), n = 100, legend.show = FALSE) +
	# prediction raster
  tm_shape(mask(pred, study_area)) +
	tm_raster(alpha = 0.5, palette = RColorBrewer::brewer.pal(name = "Reds", 6),
	          auto.palette.mapping = FALSE, legend.show = TRUE,
	          title = "Susceptibility\nprobability") +
	# rectangle and outer margins
  qtm(rect, fill = NULL) +
	tm_layout(outer.margins = c(0.04, 0.04, 0.02, 0.02), frame = FALSE,
	          legend.position = c("left", "bottom"),
	          legend.title.size = 0.9)
```

4) Compute a 100-repeated 5-fold non-spatial cross-validation and spatial CV based on the GLM learner and compare the AUROC values from both resampling strategies with the help of boxplots (see this [Figure](https://geocompr.robinlovelace.net/spatial-cv.html#fig:boxplot-cv).
Hint: You need to specify a non-spatial task and a non-spatial resampling strategy.

```{r, eval=FALSE}
# attach data (in case you have skipped exercises 1) and 2)
data("lsl", package = "spDataLarge")  # landslide points with terrain attributes

# put the coordinates in an additional dataframe
coords = lsl[, c("x", "y")]
data = dplyr::select(lsl, -x, -y)
# data_nonspatial = dplyr::select(data, -x, -y)

# CREATE TASKS
#*************

# spatial task
task = makeClassifTask(data = data, target = "lslpts", 
                       positive = "TRUE", coordinates = coords)
# non-spatial task
task_nsp = makeClassifTask(data = data, target = "lslpts", positive = "TRUE")

# CONSTRUCT LEARNER
#******************

lrn = makeLearner(cl = "classif.binomial",
                  link = "logit",
                  predict.type = "prob")

# DEFINE RESAMPLING STRATEGY
#***************************

# 100-repeated 5-fold spatial resampling strategy
resampling = makeResampleDesc(method = "SpRepCV", folds = 5, reps = 100)
# 100-repeated 5-fold non-spatial resampling strategy
resampling_nsp = makeResampleDesc(method = "RepCV", folds = 5, reps = 100)

# (SPATIAL) CROSS-VALIDATAION
#****************************

# execute the resampling
sp_cv = mlr::resample(learner = lrn, task = task,
                      resampling = resampling,
                      measures = mlr::auc)
conv_cv = mlr::resample(learner = lrn, task = task_nsp,
                        resampling = resampling_nsp,
                        measures = mlr::auc)
# Visualization of non-spatial overfitting
boxplot(sp_cv$measures.test$auc,
        conv_cv$measures.test$auc, col = c("lightblue2", "mistyrose2"),
        names = c("spatial CV", "conventional CV"), ylab = "AUROC")
```

5) Model landslide susceptibility using a quadratic discriminant analysis (QDA).
Assess the predictive performance of the QDA. 
What is the a difference between the spatially cross-validated mean AUROC value of the QDA and the GLM?
Hint: Before running the spatial cross-validation for both learners set a seed to make sure that both use the same partitions which in turn guarantees comparability.

```{r, eval=FALSE}
# attach data (in case you have skipped exercises 1) and 2)
data("lsl", package = "spDataLarge")  # landslide points with terrain attributes

# put the coordinates in an additional dataframe
coords = lsl[, c("x", "y")]
data = dplyr::select(lsl, -x, -y)
# data_nonspatial = dplyr::select(data, -x, -y)

# CREATE TASKS
#*************

# spatial task
task = makeClassifTask(data = data, target = "lslpts", 
                       positive = "TRUE", coordinates = coords)

# CONSTRUCT LEARNER
#******************

lrn_glm = makeLearner(cl = "classif.binomial",
                      link = "logit",
                      predict.type = "prob")
lrn_qda = makeLearner(cl = "classif.qda",
                      predict.type = "prob")

# find out about the models to be fitted
# getTaskFormula(task)
# train(learner = lrn_glm, task = task)
# getLearnerModel(train(learner = lrn_glm, task = task))
# train(learner = lrn_qda, task = task)
# getLearnerModel(train(learner = lrn_qda, task = task))

# DEFINE RESAMPLING STRATEGY
#***************************

# 100-repeated 5-fold spatial resampling strategy
resampling = makeResampleDesc(method = "SpRepCV", folds = 5, reps = 100)

# (SPATIAL) CROSS-VALIDATAION
#****************************

# execute the resampling
sp_glm = mlr::resample(learner = lrn_glm, task = task,
                       resampling = resampling,
                       measures = mlr::auc)
sp_qda = mlr::resample(learner = lrn_qda, task = task_nsp,
                       resampling = resampling_nsp,
                       measures = mlr::auc)
# QDA has higher AUROC values on average which indicates moderately non-linear
# boundaries
boxplot(sp_glm$measures.test$auc,
        sp_qda$measures.test$auc, col = c("lightblue2", "mistyrose2"),
        names = c("GLM", "QDA"), ylab = "AUROC")
```

6) Run the SVM without tuning the hyperparameters.
Use the `rbfdot` kernel with $\sigma$ = 1 and *C* = 1. 
Leaving the hyperparameters unspecified in **kernlab**'s `ksvm()` would otherwise initialize an automatic non-spatial hyperparameter tuning.

```{r, eval=FALSE}
# attach data (in case you have skipped exercises 1) and 2)
data("lsl", package = "spDataLarge")  # landslide points with terrain attributes

# put the coordinates in an additional dataframe
coords = lsl[, c("x", "y")]
data = dplyr::select(lsl, -x, -y)
# data_nonspatial = dplyr::select(data, -x, -y)

# CREATE TASK
#*************

# spatial task
task = makeClassifTask(data = data, target = "lslpts", 
                       positive = "TRUE", coordinates = coords)


# CONSTRUCT LEARNER
#******************
lrn_ksvm = makeLearner("classif.ksvm",
                       predict.type = "prob",
                       kernel = "rbfdot",
                       C = 1,
                       sigma = 1)

# RESAMPLING
#***********
# 100-repeated 5-fold spatial cross-validation without any hyperparameter 
# tuning
resampling = makeResampleDesc("SpRepCV", folds = 5, reps = 100)

# parallel processing not really necessary (only 500 models)
# library(parallelMap)
# parallelStart(mode = "multicore", level = "mlr.resample", 
#               cpus = parallel::detectCores() / 2)

set.seed(28032018)
resa_svm_spatial = mlr::resample(learner = lrn_ksvm, 
                                 task = task,
                                 resampling = resampling,
                                 measures = mlr::auc,
                                 show.info = TRUE)
# Aggregated Result: auc.test.mean=0.7843021
# parallelStop()
```

